{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9667473-7f9f-40e3-a475-5bcf98e45dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01cd2c43-cfec-4fbf-8c6e-a9f7a703ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook does several things, including:\n",
    "    # 1. Removes precision and T2V annotations for instances where coverage was set to -1 due to display issues\n",
    "    # 2. Joins in the utility and fluency results from the re-done human evaluation\n",
    "    # 2. Ensures each dataset is represented by 120 query-generation pairs per OP instantiation\n",
    "    # 3. Joins in Vertex API results about which sentences require citation (resolves discrepancies in sentence parsing)\n",
    "    # 4. Creates a copy of results with data only for sentences requiring citation\n",
    "\n",
    "data_str = 'nq'\n",
    "baselines = False\n",
    "\n",
    "op_fps = {'nq': '../mturk_results/unprocessed_results/nq_mturk_with_needs_citation_labels2',\n",
    "       'mh': '../mturk_results/unprocessed_results/mh_mturk_with_needs_citation_labels',\n",
    "       'mash': '../mturk_results/unprocessed_results/mash_mturk_with_needs_citation_labels',\n",
    "       'eli3': '../mturk_results/unprocessed_results/eli3_mturk_with_needs_citation_labels',\n",
    "      }\n",
    "baseline_fps = {'nq': '../mturk_results/unprocessed_results/nq_baseline_mturk_with_needs_citation_labels',\n",
    "       'mh': '../mturk_results/unprocessed_results/mh_baseline_mturk_with_needs_citation_labels',\n",
    "       'mash': '../mturk_results/unprocessed_results/mash_baseline_mturk_with_needs_citation_labels',\n",
    "       'eli3': '../mturk_results/unprocessed_results/eli3_baseline_mturk_with_needs_citation_labels',\n",
    "      }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137492f3-6f19-435a-97eb-338038468cc4",
   "metadata": {},
   "source": [
    "# Remove irrelevant T2V and precision annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd0cb082-3931-4798-afff-d76d16f5993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_irrelevant_t2v_and_precision_annotations(df):\n",
    "    # Occasionally, the annotation interface fails to display a cited sentence (coverage = -1). \n",
    "    # In these cases, precision and T2V were still collected. This function identifies and removes these measurements.\n",
    "    idxs_ops_of_interest = []\n",
    "    for i in range(len(df)):\n",
    "        if (df['op'].iloc[i] == 'Snippet'):\n",
    "            continue\n",
    "        t2vs = eval(df['t2v_coverage'].iloc[i])\n",
    "        is_covered = eval(df['is_covered'].iloc[i])\n",
    "        is_precise = eval(df['precise_citations'].iloc[i])\n",
    "        actual_is_covered = []\n",
    "        actual_is_precise = []\n",
    "        for j in range(len(is_covered)):\n",
    "            cov_item = is_covered[j]\n",
    "            if (cov_item['coverage'] != -1):\n",
    "                actual_is_covered.append(cov_item)\n",
    "            prec_item = is_precise[j]\n",
    "            if (len(prec_item['annotations'])!=0):\n",
    "                actual_is_precise.append(prec_item)\n",
    "            \n",
    "        if ((len(actual_is_covered) != len(t2vs)) or \\\n",
    "            (len(actual_is_covered) != len(actual_is_precise))):\n",
    "            query_id = df['query_id'].iloc[i]\n",
    "            op = df['op'].iloc[i]\n",
    "            idxs_ops_of_interest.append((query_id, op))\n",
    "            is_precise = eval(df['precise_citations'].iloc[i])\n",
    "            new_is_precise = []\n",
    "            for j in range(len(is_covered)):\n",
    "                coverage_item = is_covered[j]\n",
    "                if (coverage_item['coverage']!=-1):\n",
    "                    new_is_precise.append(is_precise[j])\n",
    "                else:\n",
    "                    new_is_precise.append({\"annotations\":[],\"sentence_id\":coverage_item[\"sentence_id\"]})\n",
    "    \n",
    "            if (len(is_covered)==len(t2vs)): # all of the sentences have a citation, but some weren't displayed properly\n",
    "                new_t2vs = []\n",
    "                for j in range(len(is_covered)):\n",
    "                    coverage_item = is_covered[j]\n",
    "                    if (coverage_item['coverage']!=-1):\n",
    "                        new_t2vs.append(t2vs[j])\n",
    "\n",
    "            elif (len(is_covered) > len(t2vs)): # some of the sentences had no citations and some weren't displayed properly\n",
    "                new_t2vs = []\n",
    "                k = 0 # will be used to index into t2vs\n",
    "                for j in range(len(is_covered)):\n",
    "                    coverage_item = is_covered[j]\n",
    "                    precision_item = is_precise[j]\n",
    "                    if (not ((coverage_item['coverage']==-1) and (len(precision_item['annotations'])==0))): # if T2V recorded for this sentence\n",
    "                        if (coverage_item['coverage']!=-1): # if the sentence was displayed correctly\n",
    "                            new_t2vs.append(t2vs[k]) # keep the corresponding t2v\n",
    "                        k += 1\n",
    "            else:\n",
    "                print('!!!!!! not handled')    \n",
    "                \n",
    "            \n",
    "            df['precise_citations'].iloc[i] = str(new_is_precise)\n",
    "            df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
    "\n",
    "    # print('Corrected:', idxs_ops_of_interest)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "086c7d73-4bad-46cc-90c3-aa697fd0b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_annotations(df):\n",
    "    # checks whether all precision and T2V annotations are consistent with the coverage dict\n",
    "    df = df[df['op']!='Snippet']\n",
    "    \n",
    "    idxs_ops_of_interest = []\n",
    "    for i in range(len(df)):\n",
    "        t2vs = eval(df['t2v_coverage'].iloc[i])\n",
    "        is_covered = eval(df['is_covered'].iloc[i])\n",
    "        is_precise = eval(df['precise_citations'].iloc[i])\n",
    "        actual_is_covered = []\n",
    "        actual_is_precise = []\n",
    "        for j in range(len(is_covered)):\n",
    "            cov_item = is_covered[j]\n",
    "            if (cov_item['coverage'] != -1):\n",
    "                actual_is_covered.append(cov_item)\n",
    "            prec_item = is_precise[j]\n",
    "            if (len(prec_item['annotations'])!=0):\n",
    "                actual_is_precise.append(prec_item)\n",
    "        if (len(actual_is_covered) != len(t2vs)):\n",
    "            print(df['query_id'].iloc[i])\n",
    "            print('is_precise', is_precise)\n",
    "            print('actual_is_covered len', len(actual_is_covered))\n",
    "            print('actual_is_covered', actual_is_covered)\n",
    "            print('is_covered len', len(is_covered))\n",
    "            print('t2vs', t2vs)\n",
    "            print('t2vs len', len(t2vs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df20b546-9052-4462-9a4d-9a46d4228a31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['precise_citations'].iloc[i] = str(new_is_precise)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n",
      "/var/folders/w_/zs4f9qhx30b50tppzwrnhx2c0000gn/T/ipykernel_93530/1350397303.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['t2v_coverage'].iloc[i] = str(new_t2vs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed T2V and precision annotations corresponding to cases where annotation did not occur.\n"
     ]
    }
   ],
   "source": [
    "baseline_dfs = {}\n",
    "op_dfs = {}\n",
    "\n",
    "for data_str in baseline_fps.keys():\n",
    "    baseline_dfs[data_str] = pd.read_csv(baseline_fps[data_str]+'.csv', index_col=False)\n",
    "    op_dfs[data_str] = pd.read_csv(op_fps[data_str]+'.csv', index_col=False)\n",
    "\n",
    "for baselines in [False, True]:\n",
    "    for data_str in baseline_fps.keys():\n",
    "        if (baselines):\n",
    "            df_dict = baseline_dfs\n",
    "        else:\n",
    "            df_dict = op_dfs\n",
    "            \n",
    "        df = df_dict[data_str]\n",
    "        df_dict[data_str] = remove_irrelevant_t2v_and_precision_annotations(df)\n",
    "        check_annotations(df_dict[data_str])\n",
    "        \n",
    "print('Removed T2V and precision annotations corresponding to cases where annotation did not occur.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026cfba2-09c9-4946-a23c-6943ef89ba91",
   "metadata": {},
   "source": [
    "# Drop instances with scraping issues from Gemini Mash\n",
    "Some were accidentally included in the mturk annotation. They only happened for the MASH dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3572c672-8352-4b06-8f39-8dfc892cd6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = baseline_dfs['mash']\n",
    "\n",
    "idx_to_drop = []\n",
    "for i in range(len(df)):\n",
    "    output = df['Output (cited)'].iloc[i]\n",
    "    if ('...' in output):\n",
    "        # print(df['query_id'].iloc[i])\n",
    "        # print(output)\n",
    "        # print()\n",
    "        idx_to_drop.append(i)\n",
    "\n",
    "for i in idx_to_drop:\n",
    "    df = df.drop(i)\n",
    "    \n",
    "for i in range(len(df)):\n",
    "    output = df['Output (cited)'].iloc[i]\n",
    "    if (df['op'].iloc[i] != 'Gemini'):\n",
    "        continue\n",
    "    if ('...' in output):\n",
    "        print(df['query_id'].iloc[i])\n",
    "        print(output)\n",
    "        print()\n",
    "\n",
    "baseline_dfs['mash'] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49203450-00cd-4d3e-a66f-3ecfcc40b7c3",
   "metadata": {},
   "source": [
    "# Add in the utility and fluency results\n",
    "We evaluated utility and fluency over all of the operating points simultaneously to avoid batching effects over subsets of the operating points. Here, we merge those results in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b10134e6-d790-468b-9f4c-9e7f7d7f8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_uf_results(df, baselines, data_str, verbose=False):\n",
    "    uf_fp_dict = {\n",
    "        'nq':'../mturk_results/unprocessed_results/mturk_all_nq_uf_annotations_rows.csv',\n",
    "        'mh':'../mturk_results/unprocessed_results/mturk_all_mh_uf_annotations_rows.csv',\n",
    "        'eli3':'../mturk_results/unprocessed_results/mturk_all_eli3_uf_annotations_rows.csv',\n",
    "        'mash':'../mturk_results/unprocessed_results/mturk_all_mash_uf_annotations_rows.csv'\n",
    "    }\n",
    "    uf_fp = uf_fp_dict[data_str]\n",
    "    uf_df = pd.read_csv(uf_fp, index_col=False)\n",
    "    if (baselines):\n",
    "        uf_df = uf_df[uf_df['op'].isin(['Gemini', 'Post Hoc', 'Quoted Reeval'])][['human_fluency_rating','human_utility_rating','op','query_id']]\n",
    "    else:\n",
    "        uf_df = uf_df[uf_df['op'].isin(['Snippet','Quoted','Paraphrased','Entailed','Abstractive'])][['human_fluency_rating','human_utility_rating','op','query_id']]\n",
    "\n",
    "    if (verbose): # print out all of the (query_id, op) tuples that are missing an anotation\n",
    "        missing_items = []\n",
    "        for i in range(len(df)):\n",
    "            query_id = df['query_id'].iloc[i]\n",
    "            op = df['op'].iloc[i]\n",
    "            if (len(uf_df[(uf_df['query_id']==query_id)&(uf_df['op']==op)])==0):\n",
    "                missing_items.append((query_id, op))\n",
    "        print('Missing:', len(missing_items)) # the reeval did not include the quoted reeval examples, nor were all original samples evaluated due to per-annotator sampling constraints \n",
    "        print('Found:', len(df)-len(missing_items))\n",
    "        print()\n",
    "                \n",
    "    df = df.rename({'human_fluency_rating': 'first_human_fluency_rating', 'human_utility_rating': 'first_human_utility_rating'}, axis='columns')\n",
    "    df = pd.merge(df, uf_df, how='inner', on=['query_id', 'op'])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45635274-5915-488d-8e92-3d2587b95d5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added fluency and perceived utility results for nq OPs\n",
      "Added fluency and perceived utility results for nq baselines\n",
      "Added fluency and perceived utility results for mh OPs\n",
      "Added fluency and perceived utility results for mh baselines\n",
      "Added fluency and perceived utility results for mash OPs\n",
      "Added fluency and perceived utility results for mash baselines\n",
      "Added fluency and perceived utility results for eli3 OPs\n",
      "Added fluency and perceived utility results for eli3 baselines\n"
     ]
    }
   ],
   "source": [
    "for data_str in baseline_fps.keys():\n",
    "    for baselines in [False, True]:\n",
    "        if (baselines):\n",
    "            s = ' baselines'\n",
    "        else:\n",
    "            s = ' OPs'\n",
    "        if (baselines):\n",
    "            df_dict = baseline_dfs\n",
    "        else:\n",
    "            df_dict = op_dfs\n",
    "        df = df_dict[data_str]\n",
    "        df = add_uf_results(df, baselines, data_str, verbose=False)\n",
    "        df_dict[data_str] = df\n",
    "\n",
    "        if (baselines):\n",
    "            fp = baseline_fps[data_str]\n",
    "        else:\n",
    "            fp = op_fps[data_str]\n",
    "        fp = fp.split('/')[-1]\n",
    "        save_path = '../mturk_results/intermediate_results/'+fp+'_cleaned_minus_one_coverage_UF.csv' # Used later for data over all sentences (requiring and not requiring citation)\n",
    "        df.to_csv(save_path)\n",
    "            \n",
    "        print('Added fluency and perceived utility results for '+data_str+s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f00d90-867d-45e1-93b2-bfe52cdf0d2e",
   "metadata": {},
   "source": [
    "# Ensure there are 120 queries per method\n",
    "First, check to see how much can be kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "125fd08b-338a-48c2-baed-7eb4f1d5a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trimmed_annotations_soft(df, n):\n",
    "    query_counts_by_method = df.groupby('op')['query_id'].count()\n",
    "    methods = df.groupby('op')['query_id'].count().index\n",
    "    for i in range(len(query_counts_by_method)):\n",
    "        assert query_counts_by_method.iloc[i] >= n\n",
    "        if (query_counts_by_method.iloc[i] < n):\n",
    "            print('\\tNeed more for '+methods[i]+': '+str(n-query_counts_by_method.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b832826-0f68-4e2d-aede-0d339d569a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_str in baseline_fps.keys():\n",
    "    for baselines in [False, True]:\n",
    "        if (baselines):\n",
    "            df_dict = baseline_dfs\n",
    "        else:\n",
    "            df_dict = op_dfs\n",
    "        df = df_dict[data_str]\n",
    "        check_trimmed_annotations_soft(df, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45b7bada-1871-42fa-88d6-3115d8f8de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trimmed_annotations(df, n):\n",
    "    query_counts_by_method = df.groupby('op')['query_id'].count()\n",
    "    for i in range(len(query_counts_by_method)):\n",
    "        assert query_counts_by_method[i] == n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd84961d-bed7-49ab-b853-17f3004d8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_annotations(df, n):\n",
    "    trimmed_df = df.iloc[:0]\n",
    "    ops = np.unique(df['op'])\n",
    "    trimmed_op_df_ls = []\n",
    "    for op in ops:\n",
    "        op_df = df[df['op']==op]\n",
    "        op_df = op_df.sort_values(by='query_id')\n",
    "        op_df = op_df.iloc[:n]\n",
    "        trimmed_op_df_ls.append(op_df)\n",
    "    trimmed_df = pd.concat(trimmed_op_df_ls, ignore_index=True)\n",
    "    return trimmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09695113-af91-4c03-b0c1-508140ccb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 120\n",
    "\n",
    "for data_str in baseline_fps.keys():\n",
    "    for baselines in [False, True]:\n",
    "        if (baselines):\n",
    "            df_dict = baseline_dfs\n",
    "        else:\n",
    "            df_dict = op_dfs\n",
    "        df = df_dict[data_str]\n",
    "                    \n",
    "        trim_annotations(df, n)\n",
    "        df_dict[data_str] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e29268e-28f2-452a-a472-46736176601e",
   "metadata": {},
   "source": [
    "# Create the results files accounting for \"needs citation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2a7ebd8-1902-46fd-9625-5df69c689032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_mismatches(df):\n",
    "    # The Vertex API sometimes parses sentences differently than our implementation. We resolve these conflicts by hand.\n",
    "    ids_that_need_editing = []\n",
    "    for i in range(len(df)):\n",
    "        if (df['op'].iloc[i] == 'Snippet'):\n",
    "            continue\n",
    "        gpt4_sentence_count = len(eval(df['Sent'].iloc[i]))\n",
    "        vertex_sentence_count = len(eval(df['Sentences Need Citation'].iloc[i]))\n",
    "        if (gpt4_sentence_count != vertex_sentence_count):\n",
    "            if ((all(eval(df['Sentences Need Citation'].iloc[i]))) & (vertex_sentence_count > gpt4_sentence_count)):\n",
    "                pass\n",
    "            else:\n",
    "                print('MISMATCH')\n",
    "                print(i)\n",
    "                print('(\\''+df['op'].iloc[i]+'\\', \\''+str(df['query_id'].iloc[i])+'\\')')\n",
    "                print('curr sentence count:', gpt4_sentence_count)\n",
    "                print('sentences:', df['Sent'].iloc[i])\n",
    "                print('vertex sentence count:', vertex_sentence_count)\n",
    "                print('curr vertex label:', eval(df['Sentences Need Citation'].iloc[i]))\n",
    "                print()\n",
    "                ids_that_need_editing.append(i)\n",
    "    print(ids_that_need_editing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6026b0d-71e0-4e6a-94a1-74f32be6fed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing nq Baseline=False\n",
      "nq\n",
      "MISMATCH\n",
      "18\n",
      "('Abstractive', '276')\n",
      "curr sentence count: 1\n",
      "sentences: [\"'Yo Gabba Gabba!' showcases five main characters: Muno, a red cyclops; Foofa, a pink flower bubble; Brobee, a little green creature resembling a mix of broccoli and a bee; Toodee, a blue cat-dragon; and Plex, a yellow robot.\"]\n",
      "vertex sentence count: 2\n",
      "curr vertex label: [False, True]\n",
      "\n",
      "MISMATCH\n",
      "58\n",
      "('Abstractive', '293')\n",
      "curr sentence count: 1\n",
      "sentences: [\"'I Write Sins Not Tragedies' by Panic! at the Disco is a song that centers around a wedding narrative.\"]\n",
      "vertex sentence count: 2\n",
      "curr vertex label: [False, True]\n",
      "\n",
      "MISMATCH\n",
      "122\n",
      "('Quoted', '389')\n",
      "curr sentence count: 8\n",
      "sentences: [\"'Hasta la vista, baby' is a catchphrase associated with Arnold Schwarzenegger's titular character from the 1991 science fiction action film Terminator 2: Judgment Day.\", \"The term hasta la vista (lit.\\u2009'until the view') is a Spanish farewell that can generally be understood as meaning 'Until the (next) time we see each other' or 'See you later' or 'Goodbye'.\", \"This term, with the added word 'baby'—'Hasta la vista, baby'—was later used in a popular hit song from 1987, 'Looking for a New Love' by Grammy Award winner Jody Watley.\", \"It was also used in the 1988 Tone Lōc single 'Wild Thing'.\", 'Director James Cameron revealed to FANDOM the origin of the line.', \"'I was probably working out before I went to write for the day.\", 'There was a Tone Loc video — I think it’s Wild Thing — and he says ‘hasta la vista, baby.’', \"And I thought ‘oh that works!'\"]\n",
      "vertex sentence count: 9\n",
      "curr vertex label: [True, True, True, True, True, True, False, True, False]\n",
      "\n",
      "MISMATCH\n",
      "151\n",
      "('Quoted', '293')\n",
      "curr sentence count: 1\n",
      "sentences: [\"'I Write Sins Not Tragedies' is a song by American rock band Panic! at the Disco.\"]\n",
      "vertex sentence count: 2\n",
      "curr vertex label: [True, False]\n",
      "\n",
      "MISMATCH\n",
      "260\n",
      "('Entailed', '293')\n",
      "curr sentence count: 1\n",
      "sentences: [\"'I Write Sins Not Tragedies' is a song by Panic! at the Disco.\"]\n",
      "vertex sentence count: 2\n",
      "curr vertex label: [False, False]\n",
      "\n",
      "MISMATCH\n",
      "315\n",
      "('Quoted', '343')\n",
      "curr sentence count: 1\n",
      "sentences: ['At 11:15 a.m. British Standard Time (BST) the Prime Minister Neville Chamberlain announces to the public that Britain is at war with Germany.']\n",
      "vertex sentence count: 2\n",
      "curr vertex label: [False, True]\n",
      "\n",
      "MISMATCH\n",
      "336\n",
      "('Paraphrased', '293')\n",
      "curr sentence count: 1\n",
      "sentences: ['\"I Write Sins Not Tragedies\" is a track performed by the American rock group Panic! at the Disco.']\n",
      "vertex sentence count: 2\n",
      "curr vertex label: [True, False]\n",
      "\n",
      "MISMATCH\n",
      "426\n",
      "('Quoted', '408')\n",
      "curr sentence count: 4\n",
      "sentences: ['The Currency Act or Paper Bills of Credit Act is one of several Acts of the Parliament of Great Britain that regulated paper money issued by the colonies of British America.', 'The first Act, the Currency Act 1751 (24 Geo. 2. c. 53), restricted the issue of paper money and the establishment of new public banks by the colonies of New England.', 'The Currency Act 1764 (4 Geo. 3. c. 34) extended the 1751 Act to all of the British colonies of North America.', 'Benjamin Franklin, a colonial agent in London, lobbied for repeal of the Act over the next several years, as did other agents.']\n",
      "vertex sentence count: 7\n",
      "curr vertex label: [True, True, True, True, False, True, True]\n",
      "\n",
      "MISMATCH\n",
      "579\n",
      "('Paraphrased', '340')\n",
      "curr sentence count: 1\n",
      "sentences: ['In Andhra Pradesh, India, the presiding officer of the legislative council is K. M. Raju.']\n",
      "vertex sentence count: 2\n",
      "curr vertex label: [True, False]\n",
      "\n",
      "[18, 58, 122, 151, 260, 315, 336, 426, 579]\n",
      "Showing mh Baseline=False\n",
      "mh\n",
      "MISMATCH\n",
      "27\n",
      "('Quoted', '163')\n",
      "curr sentence count: 4\n",
      "sentences: ['The University of Bergamo, known colloquially as UniBg, is an Italian public university located in Bergamo, Italy.', 'It was founded on 11 December 1968.', 'Kazakh- British Technical University, or KBTU is a research and educational institution located in Almaty, Kazakhstan.', 'It was founded in 2001.']\n",
      "vertex sentence count: 3\n",
      "curr vertex label: [True, True, True]\n",
      "\n",
      "MISMATCH\n",
      "55\n",
      "('Quoted', '201')\n",
      "curr sentence count: 3\n",
      "sentences: ['Gandu Bherunda is a 1984 Indian Kannada language drama film directed by Rajendra Singh Babu.', 'S. V. Rajendra Singh is a Kannada film maker and producer.', 'He was born and brought up in Mysore.']\n",
      "vertex sentence count: 4\n",
      "curr vertex label: [True, False, True, True]\n",
      "\n",
      "MISMATCH\n",
      "160\n",
      "('Quoted', '76')\n",
      "curr sentence count: 2\n",
      "sentences: ['S. V. Krishna Reddy (Satti Venkata Krishna Reddy) is an Indian film director, actor, producer, screenwriter and composer of Gunshot is 1996 Telugu mystery film.', 'He has garnered three state Nandi Awards and the Filmfare Best Telugu Director Award.']\n",
      "vertex sentence count: 3\n",
      "curr vertex label: [False, True, True]\n",
      "\n",
      "MISMATCH\n",
      "189\n",
      "('Paraphrased', '155')\n",
      "curr sentence count: 2\n",
      "sentences: [\"The soundtrack for 'Andru Kanda Mugam' was composed by K. V. Mahadevan.\", 'Born on March 14, 1918, Krishnankoil Venkadachalam Mahadevan was a celebrated Indian composer, musician, music producer, and singer-songwriter, who passed away on June 21, 2001.']\n",
      "vertex sentence count: 3\n",
      "curr vertex label: [True, False, True]\n",
      "\n",
      "MISMATCH\n",
      "407\n",
      "('Abstractive', '116')\n",
      "curr sentence count: 1\n",
      "sentences: ['The director of \"Let George Do It!\" Marcel Varnel, was from France.']\n",
      "vertex sentence count: 2\n",
      "curr vertex label: [False, True]\n",
      "\n",
      "MISMATCH\n",
      "481\n",
      "('Quoted', '116')\n",
      "curr sentence count: 3\n",
      "sentences: [\"Let George Do It! (US: 'To Hell With Hitler') is a 1940 British black-and-white comedy musical war film directed by Marcel Varnel.\", 'Marcel Varnel (16 October 1892 – 13 July 1947) was a film director.', 'He was born Marcel Hyacinthe le Bozec in Paris, France.']\n",
      "vertex sentence count: 4\n",
      "curr vertex label: [False, True, True, True]\n",
      "\n",
      "MISMATCH\n",
      "510\n",
      "('Quoted', '155')\n",
      "curr sentence count: 2\n",
      "sentences: ['Music was by K. V. Mahadevan.', 'Krishnankoil Venkadachalam Mahadevan (14 March 1918 – 21 June 2001) was an Indian composer, singer-songwriter, music producer, and musician.']\n",
      "vertex sentence count: 3\n",
      "curr vertex label: [True, False, True]\n",
      "\n",
      "MISMATCH\n",
      "589\n",
      "('Quoted', '197')\n",
      "curr sentence count: 2\n",
      "sentences: ['Alhaji Sir Ahmadu Bello KBE (June 12, 1910 – January 15, 1966)', 'Paulette Noizeux (30 May 1887 – 9 April 1971)']\n",
      "vertex sentence count: 1\n",
      "curr vertex label: [True]\n",
      "\n",
      "MISMATCH\n",
      "609\n",
      "('Quoted', '98')\n",
      "curr sentence count: 4\n",
      "sentences: ['Jai is a 2004 Telugu drama film directed by Teja.', 'Teja( born Dharma Teja Jasti, 22 February 1966) is an Indian cinematographer turned director, known for his works in Telugu cinema and Bollywood.', '3 Ring Circus is a 1954 American comedy film directed by Joseph Pevney.', 'Joseph Pevney (September 15, 1911 – May 18, 2008) was an American film and television director.']\n",
      "vertex sentence count: 3\n",
      "curr vertex label: [True, True, True]\n",
      "\n",
      "[27, 55, 160, 189, 407, 481, 510, 589, 609]\n",
      "Showing mash Baseline=False\n",
      "mash\n",
      "MISMATCH\n",
      "88\n",
      "('Quoted', '139')\n",
      "curr sentence count: 9\n",
      "sentences: ['If these symptoms occur within 72 hours of the biopsy, call your doctor or go to the nearest emergency room:', 'Fever', 'Dizziness', 'Chills', 'Difficulty breathing', 'Chest pain', 'Abdominal swelling or bloating', 'Increasing abdominal pain', 'Tenderness or severe pain or redness at the site of the biopsy or in the shoulder, chest, or abdomen']\n",
      "vertex sentence count: 1\n",
      "curr vertex label: [True]\n",
      "\n",
      "MISMATCH\n",
      "118\n",
      "('Quoted', '143')\n",
      "curr sentence count: 12\n",
      "sentences: ['You may want to consider medicine to prevent migraines if you:', 'Have pain that hampers your life despite treatment', 'Get at more than three moderate to severe headaches per month', 'Take a lot of painkillers', \"Don't get enough relief from meds you now take\", 'Have side effects from your headache drugs', 'Have uncommon migraine conditions like continuing aura.', 'Preventive medicine might not be right for you if:', 'Your headaches are infrequent and controlled by anti-inflammatories like ibuprofen and naproxen.', 'Other health conditions keep you from taking preventive drugs.', 'Those drugs could mix badly with other medicines you take.', \"You prefer treatments that don't involve meds.\"]\n",
      "vertex sentence count: 5\n",
      "curr vertex label: [True, True, True, True, True]\n",
      "\n",
      "MISMATCH\n",
      "149\n",
      "('Quoted', '123')\n",
      "curr sentence count: 12\n",
      "sentences: [\"Cushing's syndrome is all about the stress hormone cortisol.\", \"When your body has too much of it, the excess hormone can throw off your body's other systems.\", \"The recommended treatments involve if you have too much cortisol because you're taking steroid medicines, your doctor will check to see if you can stop taking the drugs, or take a lower dose.\", \"If a tumor is causing your Cushing's syndrome, you'll likely have other tests to determine the location of the tumor first before deciding on your treatment.\", 'Surgery to remove the tumor may be best.', 'If not, your doctor may be able to shrink the tumor with radiation or medicine.', \"For lifestyle changes, it's advised to Protect your bones by eating foods with calcium and vitamin D.\", 'Limit how much sodium and fatty foods you eat.', \"Additionally, Let your family and friends know what you're going through.\", 'Ask for their support, and let them know how they can help.', 'Take time for the people and activities you enjoy.', \"It's OK to say no and set limits, so you keep your energy up.\"]\n",
      "vertex sentence count: 11\n",
      "curr vertex label: [True, True, True, True, True, True, True, False, False, False, True]\n",
      "\n",
      "MISMATCH\n",
      "225\n",
      "('Quoted', '130')\n",
      "curr sentence count: 6\n",
      "sentences: ['To eat and drink properly for stronger bones, Get more calcium and vitamin D in your diet to keep bones healthy.', 'You can Enjoy low-fat dairy products or dark, leafy green veggies to get calcium from natural sources.', 'Additionally, Get vitamin D in egg yolks, ocean fish, and liver.', 'This approach is crucial because Inflammation also may make it harder for your body to absorb nutrients it needs to keep your bones strong, like calcium or vitamin D.', 'Furthermore, Exercise helps you develop flexible joints, stronger muscles, and better balance with RA.', 'It also can help you protect your bones from osteoporosis because it builds bone mass.']\n",
      "vertex sentence count: 5\n",
      "curr vertex label: [True, True, True, True, True]\n",
      "\n",
      "MISMATCH\n",
      "320\n",
      "('Paraphrased', '130')\n",
      "curr sentence count: 5\n",
      "sentences: ['For optimal bone health, increase your intake of calcium and vitamin D.', 'Consuming low-fat dairy or dark, leafy vegetables can provide you with a natural source of calcium.', 'For vitamin D, include egg yolks, fatty fish, and liver in your diet.', \"This is essential as inflammation can impede your body's ability to absorb critical nutrients such as calcium and vitamin D, which are vital for bone strength.\", 'Engaging in regular exercise not only enhances joint flexibility, muscle strength, and balance, particularly important for those with RA, but it also contributes to bone density, offering protection against osteoporosis by increasing bone mass.']\n",
      "vertex sentence count: 4\n",
      "curr vertex label: [True, True, True, True]\n",
      "\n",
      "MISMATCH\n",
      "361\n",
      "('Abstractive', '130')\n",
      "curr sentence count: 4\n",
      "sentences: ['For stronger bones, increase your intake of calcium and vitamin D.', 'Calcium-rich foods include low-fat dairy products and dark, leafy greens, while vitamin D can be found in egg yolks, fish, and liver.', 'Reducing inflammation through diet can also improve nutrient absorption, essential for bone health.', 'Additionally, regular exercise not only builds muscle and improves balance but also increases bone density, offering protection against osteoporosis.']\n",
      "vertex sentence count: 3\n",
      "curr vertex label: [True, True, True]\n",
      "\n",
      "MISMATCH\n",
      "561\n",
      "('Paraphrased', '135')\n",
      "curr sentence count: 10\n",
      "sentences: ['To manage a brown recluse spider bite at home, follow these steps:', 'Firstly, wash the area with soap and water.', 'Apply an antibiotic ointment to prevent infection.', 'Elevate the bitten limb to minimize swelling.', 'Use ice packs to alleviate swelling and pain.', 'For discomfort, consider taking pain relievers available over the counter.', 'Additionally, be vigilant for symptoms that indicate a more serious reaction.', 'Seek immediate medical attention if you observe a blister or ulcer with a dark center, experience severe pain, notice signs of infection at the bite site, or have difficulty breathing.', 'Moreover, since spider bites can potentially introduce tetanus spores, a tetanus booster might be necessary.', 'In cases of infection, antibiotics may be prescribed by a healthcare professional.']\n",
      "vertex sentence count: 9\n",
      "curr vertex label: [False, True, True, True, True, True, True, True, True]\n",
      "\n",
      "MISMATCH\n",
      "565\n",
      "('Quoted', '207')\n",
      "curr sentence count: 5\n",
      "sentences: [\"You should take your child to the ER for a nosebleed if You're injured or go through something traumatic, like a car accident,\", \"There's more blood than you expect for a nosebleed,\", 'It affects your ability to breathe, or The bleeding lasts longer than 20 minutes, even when you apply pressure.', \"Additionally, if He's bleeding heavily and/or they feel dizzy or weak,\", \"It happened because of a fall or an injury, or The bleeding won't stop, even after two attempts to put pressure on his nose for 10 minutes at a time.\"]\n",
      "vertex sentence count: 2\n",
      "curr vertex label: [True, False]\n",
      "\n",
      "[88, 118, 149, 225, 320, 361, 561, 565]\n",
      "Showing eli3 Baseline=False\n",
      "eli3\n",
      "MISMATCH\n",
      "24\n",
      "('Quoted', '493')\n",
      "curr sentence count: 5\n",
      "sentences: ['Cersei Lannister plots to destroy all her immediate enemies with one swift stroke;', 'Jon Snow is declared King in the North by the lords of the Northern houses;', 'Bran Stark learns that Jon is actually the son of Lyanna Stark and Rhaegar Targaryen;', 'Samwell Tarly arrives at the Citadel;', 'and Daenerys Targaryen begins heading to Westeros alongside Tyrion Lannister, her entire army, her three dragons, as well as the Ironborn loyal to Yara Greyjoy, the Tyrells, the Sand Snakes, and their respective fleets.']\n",
      "vertex sentence count: 1\n",
      "curr vertex label: [True]\n",
      "\n",
      "MISMATCH\n",
      "159\n",
      "('Paraphrased', '493')\n",
      "curr sentence count: 5\n",
      "sentences: ['Cersei Lannister comes up with a plan to get rid of all her enemies at once;', 'Jon Snow gets chosen as the King in the North by the leaders of the Northern houses;', 'Bran Stark finds out Jon is really the son of Lyanna Stark and Rhaegar Targaryen;', 'Samwell Tarly makes it to the Citadel;', 'and Daenerys Targaryen sets sail for Westeros with Tyrion Lannister, her whole army, her three dragons, and the ships of her allies, including those loyal to Yara Greyjoy, the Tyrells, the Sand Snakes, and their fleets.']\n",
      "vertex sentence count: 1\n",
      "curr vertex label: [True]\n",
      "\n",
      "MISMATCH\n",
      "179\n",
      "('Quoted', '504')\n",
      "curr sentence count: 2\n",
      "sentences: [\"I'm a Celebrity...Get Me Out of Here! is a reality television format in which a number of celebrities live together in a jungle environment for a number of weeks, competing to be crowned 'King' or 'Queen of the Jungle'.\", 'I’m A Celebrity… Get Me Out Of Here! starts on Sunday 19th of November at 9pm on ITV1 and ITVX.']\n",
      "vertex sentence count: 3\n",
      "curr vertex label: [True, False, True]\n",
      "\n",
      "MISMATCH\n",
      "428\n",
      "('Entailed', '493')\n",
      "curr sentence count: 5\n",
      "sentences: ['Cersei Lannister makes a big plan to defeat all her enemies at once;', 'Jon Snow is chosen as the King of the North;', 'Bran Stark finds out Jon is really the son of Lyanna Stark and Rhaegar Targaryen;', 'Samwell Tarly reaches a place called the Citadel;', 'and Daenerys Targaryen, with her friend Tyrion Lannister, her big army, three dragons, and some allies, starts her journey to Westeros.']\n",
      "vertex sentence count: 1\n",
      "curr vertex label: [True]\n",
      "\n",
      "MISMATCH\n",
      "500\n",
      "('Quoted', '546')\n",
      "curr sentence count: 2\n",
      "sentences: [\"'What’s in a name? That which we call a rose / By any other name would smell as sweet.'\", 'From William Shakespeare’s play Romeo and Juliet.']\n",
      "vertex sentence count: 3\n",
      "curr vertex label: [False, True, False]\n",
      "\n",
      "MISMATCH\n",
      "522\n",
      "('Abstractive', '593')\n",
      "curr sentence count: 1\n",
      "sentences: ['The first person to say \"I\\'m going to Disney World!\" after winning the Super Bowl was Phil Simms, a famous football player.']\n",
      "vertex sentence count: 2\n",
      "curr vertex label: [False, True]\n",
      "\n",
      "[24, 159, 179, 428, 500, 522]\n",
      "Showing nq Baseline=True\n",
      "['Gemini' 'Post Hoc']\n",
      "nq\n",
      "MISMATCH\n",
      "252\n",
      "('Gemini', '293')\n",
      "curr sentence count: 3\n",
      "sentences: ['Panic! at the Disco\\'s \"I Write Sins Not Tragedies\" is a popular choice for wedding songs due to its dramatic and theatrical elements.', 'The song tells a story of a wedding gone awry, focusing on the unexpected twists and turns that unfold.', \"While it doesn't directly celebrate the institution of marriage, its dramatic narrative and catchy melody make it a memorable choice for a special occasion.\"]\n",
      "vertex sentence count: 4\n",
      "curr vertex label: [False, True, True, True]\n",
      "\n",
      "[252]\n",
      "Showing mh Baseline=True\n",
      "['Gemini' 'Post Hoc']\n",
      "mh\n",
      "[]\n",
      "Showing mash Baseline=True\n",
      "['Gemini' 'Post Hoc']\n",
      "mash\n",
      "MISMATCH\n",
      "10\n",
      "('Gemini', '105')\n",
      "curr sentence count: 6\n",
      "sentences: ['Choosing the Right Grooming Products for Psoriasis', 'When selecting grooming products for psoriasis, opt for gentle, hypoallergenic options.', 'Avoid harsh ingredients like fragrances, dyes, and alcohol, as these can irritate the skin.', 'Look for products labeled \"fragrance-free,\" \"hypoallergenic,\" or \"gentle.\"', 'Additionally, consider using products specifically formulated for sensitive or irritated skin.', \"Remember to patch test new products on a small area of skin before full application to ensure you don't experience any adverse reactions.\"]\n",
      "vertex sentence count: 5\n",
      "curr vertex label: [True, True, True, True, True]\n",
      "\n",
      "MISMATCH\n",
      "22\n",
      "('Gemini', '125')\n",
      "curr sentence count: 6\n",
      "sentences: ['To wash crusty lashes due to dry eyes, follow these steps:', 'Gently moisten a clean, soft cloth with warm water.', 'Carefully wipe away the crust from the base of your lashes, moving from the inner corner to the outer corner of your eye.', 'Be gentle to avoid irritating your eyes.', 'Repeat as needed, ensuring your hands are clean to prevent infection.', 'For persistent crusting, consult an eye care professional for further advice.']\n",
      "vertex sentence count: 5\n",
      "curr vertex label: [False, False, True, True, False]\n",
      "\n",
      "MISMATCH\n",
      "63\n",
      "('Gemini', '159')\n",
      "curr sentence count: 7\n",
      "sentences: [\"To ensure your loved one with Alzheimer's disease receives adequate nutrition, consider the following strategies:\", 'Offer small, frequent meals and snacks throughout the day to avoid overwhelming them.', 'Create a calm, distraction-free dining environment.', 'Encourage self-feeding, but be prepared to assist as needed.', 'Provide finger foods and soft textures to make eating easier.', 'Monitor their intake and adjust meal plans accordingly.', 'If difficulties persist, consult a healthcare professional or a registered dietitian for personalized advice.']\n",
      "vertex sentence count: 6\n",
      "curr vertex label: [True, True, True, True, False, True]\n",
      "\n",
      "[10, 22, 63]\n",
      "Showing eli3 Baseline=True\n",
      "['Gemini' 'Post Hoc']\n",
      "eli3\n",
      "MISMATCH\n",
      "45\n",
      "('Gemini', '574')\n",
      "curr sentence count: 5\n",
      "sentences: ['Imagine building a big, beautiful house.', 'It takes a lot of planning and hard work, right?', \"Well, Dr. B.R. Ambedkar was kind of like the architect of India's constitution.\", 'He was the main person who helped design and build the rules that guide how India is run.', \"Just like an architect makes sure a house is strong and safe, Dr. Ambedkar made sure India's rules were fair and protected everyone's rights.\"]\n",
      "vertex sentence count: 6\n",
      "curr vertex label: [False, True, True, True, True, True]\n",
      "\n",
      "MISMATCH\n",
      "64\n",
      "('Gemini', '529')\n",
      "curr sentence count: 4\n",
      "sentences: ['A long time ago, there was a man named Charles Perrault who loved telling stories.', 'He wrote down a lot of fun tales, including the one about Little Red Riding Hood.', \"It's a story about a girl who wears a red hood and goes to visit her grandma.\", \"But watch out! There's a tricky wolf in the woods!\"]\n",
      "vertex sentence count: 5\n",
      "curr vertex label: [True, True, True, False, False]\n",
      "\n",
      "MISMATCH\n",
      "115\n",
      "('Gemini', '546')\n",
      "curr sentence count: 2\n",
      "sentences: ['Shakespeare\\'s famous line \"What\\'s in a name? That which we call a rose by any other name would smell as sweet\" means that the name of something doesn\\'t change its essence or value.', 'So, even if we called a rose something else, it would still smell the same and be just as beautiful.']\n",
      "vertex sentence count: 3\n",
      "curr vertex label: [False, True, True]\n",
      "\n",
      "[45, 64, 115]\n"
     ]
    }
   ],
   "source": [
    "# Display the cases that require review\n",
    "for baselines in [False, True]:\n",
    "    for data_str in baseline_fps.keys():\n",
    "        print('Showing '+data_str+' Baseline='+str(baselines))\n",
    "        if (baselines):\n",
    "            df_dict = baseline_dfs\n",
    "        else:\n",
    "            df_dict = op_dfs\n",
    "        df = df_dict[data_str]\n",
    "        \n",
    "        # Check whether we have the quoted reeval results\n",
    "        if (baselines):\n",
    "            print(np.unique(df['op']))\n",
    "        print(data_str)\n",
    "        \n",
    "        # Identify mismatches in my sentence count and the vertex sentence count\n",
    "        identify_mismatches(df)\n",
    "        # Determine the \"needs citation\" labels by hand for this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fbbeb63-fb1d-49ab-8b8b-ae45ae8f3c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cases where one or more sentences don't require citation, add their \"Sentences Need Citation\" label to a dict below\n",
    "baseline_corrections = {'mash': {\n",
    "                10: [True, True, True, True, True, True], # ('Gemini', '105')\n",
    "                22: [True, True, True, True, True, True], # ('Gemini', '125')\n",
    "                63: [True]*7, # ('Gemini', '159')\n",
    "              }, \n",
    "               'eli3': {\n",
    "                   45: [False, True, True, True, True], # ('Gemini', '574')\n",
    "                   64: [True, True, True, True], # ('Gemini', '529')\n",
    "                   115: [True, True], # ('Gemini', '546')\n",
    "                   },\n",
    "               'nq': {\n",
    "                   252: [True]*3, # ('Gemini', '293')\n",
    "               },\n",
    "               'mh': {}\n",
    "              }\n",
    "\n",
    "op_corrections = {'mash': {\n",
    "                    88: [True]*9, # ('Quoted', '139')\n",
    "                    118: [True]*12, # ('Quoted', '143')\n",
    "                    149: [True]*12, # ('Quoted', '123')\n",
    "                    225: [True]*6, # ('Quoted', '130')\n",
    "                    320: [True]*5, # ('Paraphrased', '130')\n",
    "                    361: [True]*4, # ('Abstractive', '130')\n",
    "                    561: [False]+[True]*9, # ('Paraphrased', '135')\n",
    "                    565: [True]*5, # ('Quoted', '207')\n",
    "} , \n",
    "               'eli3': {\n",
    "                   24: [True]*5, # ('Quoted', '493')\n",
    "                   159: [True]*5, # ('Paraphrased', '493')\n",
    "                   179: [True]*2, # ('Quoted', '504')\n",
    "                   428: [True]*5, # ('Entailed', '493')\n",
    "                   500: [True]*2, # ('Quoted', '546')\n",
    "                   522: [True], # ('Abstractive', '593')\n",
    "               },\n",
    "               'nq': {\n",
    "                     18: [True], # ('Abstractive', '276')\n",
    "                     58: [True], # ('Abstractive', '293')\n",
    "                     122: [True, True, True, True, True, True, True, True], # ('Quoted', '389')\n",
    "                     151: [True], # ('Quoted', '293')\n",
    "                     260: [True], # ('Entailed', '293')\n",
    "                     315: [True], # ('Quoted', '343')\n",
    "                     336: [True], # ('Paraphrased', '293')\n",
    "                     426: [True, True, True, True], # ('Quoted', '408')\n",
    "                     579: [True], # ('Paraphrased', '340')\n",
    "               },\n",
    "               'mh': {\n",
    "                   27: [True, True, True, True], # ('Quoted', '163')\n",
    "                   55: [True, True, True], # ('Quoted', '201')\n",
    "                   160: [True, True], # ('Quoted', '76')\n",
    "                   189: [True, True], # ('Paraphrased', '155')\n",
    "                   407: [True], # ('Abstractive', '116')\n",
    "                   481: [True, True, True], # ('Quoted', '116')\n",
    "                   510: [True, True], # ('Quoted', '155')\n",
    "                   589: [True, True], # ('Quoted', '197')\n",
    "                   609: [True, True, True, True], # ('Quoted', '98')\n",
    "               }\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53530962-db2e-463a-8938-25e751ad3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_mismatches(df, corrections_dict):\n",
    "    for i in range(len(df)):\n",
    "        if (df['op'].iloc[i] == 'Snippet'):\n",
    "            continue\n",
    "        gpt4_sentence_count = len(eval(df['Sent'].iloc[i]))\n",
    "        vertex_sentence_count = len(eval(df['Sentences Need Citation'].iloc[i]))\n",
    "        if (gpt4_sentence_count != vertex_sentence_count):\n",
    "            if ((all(eval(df['Sentences Need Citation'].iloc[i]))) & (vertex_sentence_count > gpt4_sentence_count)):\n",
    "                 df.loc[i, 'Sentences Need Citation'] = str([True]*gpt4_sentence_count) \n",
    "            else:\n",
    "                if (i not in corrections_dict):\n",
    "                    print(i)\n",
    "                    continue\n",
    "                df.loc[i, 'Sentences Need Citation'] = str(corrections_dict[i])\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if (df['op'].iloc[i] == 'Snippet'):\n",
    "            continue\n",
    "        gpt4_sentence_count = len(eval(df['Sent'].iloc[i]))\n",
    "        vertex_sentence_count = len(eval(df['Sentences Need Citation'].iloc[i]))\n",
    "        assert gpt4_sentence_count == vertex_sentence_count\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6c64696-278e-4e48-bc40-2bd553e3154e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed mismatches between the Vertex API and the annotated sentence count\n"
     ]
    }
   ],
   "source": [
    "# Fix the mismatches between vertex and the current sentence count\n",
    "for baselines in [False, True]:\n",
    "    for data_str in baseline_fps.keys():\n",
    "        if (baselines):\n",
    "            df_dict = baseline_dfs\n",
    "        else:\n",
    "            df_dict = op_dfs\n",
    "        df = df_dict[data_str]\n",
    "        \n",
    "        # assign the \"needs citation\" labels for the mismatch case from above\n",
    "        if (baselines):\n",
    "            corrections_dict = baseline_corrections\n",
    "        else:\n",
    "            corrections_dict = op_corrections\n",
    "            \n",
    "        df = fix_mismatches(df, corrections_dict[data_str])  \n",
    "        df_dict[data_str] = df\n",
    "print('Fixed mismatches between the Vertex API and the annotated sentence count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8bd4d8a-abf2-4d4d-9de0-fbccd16e689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_only_needs_citation(df):\n",
    "    # Remove the precision, coverage, and T2V data for sentences that do not require citation\n",
    "    # Clean up the precision and coverage annotations, given the \"needs citation labels\"\n",
    "    for i in range(len(df)):\n",
    "        if (df['op'].iloc[i] == 'Snippet'):\n",
    "            continue\n",
    "            \n",
    "        sentences_need_citation = eval(df['Sentences Need Citation'].iloc[i])\n",
    "        \n",
    "        # first the coverage\n",
    "        is_covered = eval(df['is_covered'].iloc[i])\n",
    "        new_is_covered = []\n",
    "        for j in range(len(is_covered)):\n",
    "            sentence_idx = is_covered[j]['sentence_id']\n",
    "            if (sentences_need_citation[sentence_idx]):\n",
    "                new_is_covered.append(is_covered[j])\n",
    "        df.loc[i, 'is_covered'] = str(new_is_covered)\n",
    "        assert len(eval(df['is_covered'].iloc[i])) == np.sum(sentences_need_citation)\n",
    "    \n",
    "        # now the precision\n",
    "        is_precise = eval(df['precise_citations'].iloc[i])\n",
    "        new_is_precise = []\n",
    "        for j in range(len(is_precise)):\n",
    "            item = is_precise[j]\n",
    "            sentence_idx = item['sentence_id']\n",
    "            if (sentences_need_citation[sentence_idx]):\n",
    "                new_is_precise.append(item)\n",
    "        df.loc[i, 'precise_citations'] = str(new_is_precise)\n",
    "        assert len(eval(df['precise_citations'].iloc[i])) == np.sum(sentences_need_citation)\n",
    "    \n",
    "        # now T2V\n",
    "        t2vs = eval(df['t2v_coverage'].iloc[i])\n",
    "            \n",
    "        # keep the T2V values that correspond to coverage values that a) exist and b) need citation\n",
    "        actual_coverage_items = []\n",
    "        for item in is_covered:\n",
    "            if (item['coverage'] != -1):\n",
    "                actual_coverage_items.append(item)\n",
    "\n",
    "        \n",
    "        new_t2vs = []\n",
    "        for j in range(len(actual_coverage_items)):\n",
    "            sentence_idx = actual_coverage_items[j]['sentence_id']\n",
    "            if (sentences_need_citation[sentence_idx]):\n",
    "                new_t2vs.append(t2vs[j])\n",
    "        df.loc[i, 't2v_coverage'] = str(new_t2vs)\n",
    "\n",
    "        # Now, handle the citations dict\n",
    "        actual_citations_dict = {}\n",
    "        citations_dict = eval(df['Citation Dict'].iloc[i])\n",
    "        for k in citations_dict.keys():\n",
    "            if (sentences_need_citation[int(k)]):\n",
    "                actual_citations_dict[k] = citations_dict[k]\n",
    "        df.loc[i, 'Citation Dict'] = str(actual_citations_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f93cfdb-2d52-4114-a5df-a89490e61758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_needs_citation(df):\n",
    "    for i in range(len(df)):\n",
    "        if (df['op'].iloc[i] == 'Snippet'):\n",
    "            continue\n",
    "        needs_citation_ls = eval(df['Sentences Need Citation'].iloc[i])\n",
    "        is_covered_ls = eval(df['is_covered'].iloc[i])\n",
    "        is_precise_ls = eval(df['precise_citations'].iloc[i])\n",
    "        assert np.sum(needs_citation_ls) == len(is_covered_ls)\n",
    "        assert  np.sum(needs_citation_ls) == len(is_precise_ls)\n",
    "        t2vs = eval(df['t2v_coverage'].iloc[i])\n",
    "        assert len(is_covered_ls) >= len(t2vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63625e63-899b-493e-97bc-9731db2a7b98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discard coverage, precision, and T2V annotations for sentences that do not require citation\n"
     ]
    }
   ],
   "source": [
    "for baselines in [False, True]:\n",
    "    for data_str in baseline_fps.keys():\n",
    "        if (baselines):\n",
    "            df_dict = baseline_dfs\n",
    "        else:\n",
    "            df_dict = op_dfs\n",
    "        df = df_dict[data_str]\n",
    "        # clean up the coverage, precision, and T2V annotations, given the \"needs citation labels\"\n",
    "        \n",
    "        df = make_only_needs_citation(df)\n",
    "\n",
    "        # check that only the relevant sentences are kept\n",
    "        check_needs_citation(df)\n",
    "        \n",
    "        df_dict[data_str] = df\n",
    "print('Discard coverage, precision, and T2V annotations for sentences that do not require citation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b02b41-f9d0-4955-920d-d326a90a9a08",
   "metadata": {},
   "source": [
    "# Filter the baseline quoted T2V annotations to only those that require citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b0c9dad-1153-452d-ac75-50ad5e98f198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISMATCH\n",
      "18\n",
      "('Quoted', '217')\n",
      "curr sentence count: 8\n",
      "sentences: ['With agoraphobia, you might worry when you are in: Public transportation (buses, trains, ships, or planes)', 'Large, open spaces (parking lots, bridges)', 'Closed-in spaces (stores, movie theaters)', 'Crowds or standing in line', 'Being outside your home alone.', 'You may be willing to go just a handful of places.', 'This cuts down on the chances of panic.', 'You may even dread leaving your house.']\n",
      "vertex sentence count: 4\n",
      "curr vertex label: [True, True, True, True]\n",
      "\n",
      "MISMATCH\n",
      "45\n",
      "('Quoted', '62')\n",
      "curr sentence count: 13\n",
      "sentences: [\"You should call your doctor about your child's stomach ache and nausea if The child isn't moving,\", 'The child is too weak to stand up,', 'or if the child has Pain that happens more often or gets worse,', 'Pain that moves from the belly button to the lower right of the abdomen,', 'Trouble walking because of pain,', 'No appetite for a day or longer,', 'Green or yellow vomit or vomit that contains blood or flecks that look like coffee grounds,', 'Symptoms of dehydration such as darker urine and fewer wet diapers,', 'Black or bloody stool,', 'Problems passing stool,', 'A rash that looks like bruises on the legs and buttocks,', 'Headache and sore throat along with stomach pain,', 'or Pain when urinating.']\n",
      "vertex sentence count: 1\n",
      "curr vertex label: [True]\n",
      "\n",
      "MISMATCH\n",
      "53\n",
      "('Quoted', '143')\n",
      "curr sentence count: 12\n",
      "sentences: ['You may want to consider medicine to prevent migraines if you:', 'Have pain that hampers your life despite treatment', 'Get at more than three moderate to severe headaches per month', 'Take a lot of painkillers', \"Don't get enough relief from meds you now take\", 'Have side effects from your headache drugs', 'Have uncommon migraine conditions like continuing aura.', 'Preventive medicine might not be right for you if:', 'Your headaches are infrequent and controlled by anti-inflammatories like ibuprofen and naproxen.', 'Other health conditions keep you from taking preventive drugs.', 'Those drugs could mix badly with other medicines you take.', \"You prefer treatments that don't involve meds.\"]\n",
      "vertex sentence count: 5\n",
      "curr vertex label: [True, True, True, True, True]\n",
      "\n",
      "MISMATCH\n",
      "71\n",
      "('Quoted', '139')\n",
      "curr sentence count: 9\n",
      "sentences: ['If these symptoms occur within 72 hours of the biopsy, call your doctor or go to the nearest emergency room:', 'Fever', 'Dizziness', 'Chills', 'Difficulty breathing', 'Chest pain', 'Abdominal swelling or bloating', 'Increasing abdominal pain', 'Tenderness or severe pain or redness at the site of the biopsy or in the shoulder, chest, or abdomen']\n",
      "vertex sentence count: 1\n",
      "curr vertex label: [True]\n",
      "\n",
      "MISMATCH\n",
      "96\n",
      "('Quoted', '130')\n",
      "curr sentence count: 6\n",
      "sentences: ['To eat and drink properly for stronger bones, Get more calcium and vitamin D in your diet to keep bones healthy.', 'You can Enjoy low-fat dairy products or dark, leafy green veggies to get calcium from natural sources.', 'Additionally, Get vitamin D in egg yolks, ocean fish, and liver.', 'This approach is crucial because Inflammation also may make it harder for your body to absorb nutrients it needs to keep your bones strong, like calcium or vitamin D.', 'Furthermore, Exercise helps you develop flexible joints, stronger muscles, and better balance with RA.', 'It also can help you protect your bones from osteoporosis because it builds bone mass.']\n",
      "vertex sentence count: 5\n",
      "curr vertex label: [True, True, True, True, True]\n",
      "\n",
      "MISMATCH\n",
      "100\n",
      "('Quoted', '123')\n",
      "curr sentence count: 12\n",
      "sentences: [\"Cushing's syndrome is all about the stress hormone cortisol.\", \"When your body has too much of it, the excess hormone can throw off your body's other systems.\", \"The recommended treatments involve if you have too much cortisol because you're taking steroid medicines, your doctor will check to see if you can stop taking the drugs, or take a lower dose.\", \"If a tumor is causing your Cushing's syndrome, you'll likely have other tests to determine the location of the tumor first before deciding on your treatment.\", 'Surgery to remove the tumor may be best.', 'If not, your doctor may be able to shrink the tumor with radiation or medicine.', \"For lifestyle changes, it's advised to Protect your bones by eating foods with calcium and vitamin D.\", 'Limit how much sodium and fatty foods you eat.', \"Additionally, Let your family and friends know what you're going through.\", 'Ask for their support, and let them know how they can help.', 'Take time for the people and activities you enjoy.', \"It's OK to say no and set limits, so you keep your energy up.\"]\n",
      "vertex sentence count: 11\n",
      "curr vertex label: [True, True, True, True, True, True, True, False, False, False, True]\n",
      "\n",
      "MISMATCH\n",
      "132\n",
      "('Quoted', '76')\n",
      "curr sentence count: 7\n",
      "sentences: ['To manage menopause symptoms besides taking hormone replacement therapy (HRT), one can adopt several lifestyle changes such as Dress in layers so you can remove clothes as needed.', 'Avoid hot and spicy foods and beverages.', 'Use cotton sheets, and wear clothes that allow your skin to breathe.', 'Limit caffeine and alcohol.', 'Use relaxation techniques such as yoga.', \"Don't smoke.\", 'Get regular exercise.']\n",
      "vertex sentence count: 1\n",
      "curr vertex label: [True]\n",
      "\n",
      "MISMATCH\n",
      "133\n",
      "('Quoted', '210')\n",
      "curr sentence count: 27\n",
      "sentences: [\"When diagnosed with cancer, it's crucial to make the most of your appointment by being prepared with questions for your doctor.\", 'Here are some essential questions to consider:', '', '- What kind of cancer do I have?', '- What stage is it?', '- How common is my cancer?', '- What is my prognosis?', '- What are my cancer treatment options?', '- Are these cancer treatments proven or experimental?', '- Are these cancer treatments covered by insurance?', '- What should I expect from my cancer treatment? How long will it take? How successful is it usually?', '- How will I feel? What side effects or complications could I face from my cancer treatment?', '- In addition to treatment for cancer, will I also need to take other medicines? If so, what and for how long?', '- Should I make any changes to my diet or lifestyle before starting cancer treatment?', '', \"To assess the doctor's qualifications and ensure a comfortable partnership in your cancer treatment, consider asking:\", '', '- How much experience do you have in treating people with my type of cancer?', '- How many people with my cancer have you treated in the past year?', '- Are you board certified? If so, in what specialty or subspecialty?', '- Do you have other relevant qualifications?', '- Do you work closely with other specialists and health care providers who could be part of my cancer treatment team?', '- What hospitals do you work with?', '- Would I be eligible for a clinical trial? If so, are clinical trials available at this medical center? If not, are they available in this area?', '- Can you recommend another doctor for a second opinion?', '', 'Doctors expect these questions and even welcome them, aiming for their patients to feel comfortable and confident in their care.']\n",
      "vertex sentence count: 30\n",
      "curr vertex label: [True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n",
      "\n",
      "[18, 45, 53, 71, 96, 100, 132, 133]\n"
     ]
    }
   ],
   "source": [
    "k = 'mash'\n",
    "baseline_df = pd.read_csv(baseline_fps[k]+'.csv', index_col=False).reset_index(drop=True)\n",
    "quoted_baseline_df = baseline_df[baseline_df['op']=='Quoted'].reset_index(drop=True)\n",
    "identify_mismatches(quoted_baseline_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4556bfb4-5784-4c25-88b8-6f88bb0ce221",
   "metadata": {},
   "outputs": [],
   "source": [
    "quoted_baseline_corrections = {\n",
    "            'nq': {\n",
    "                0:[True, True, True, True], # ('Quoted', '408')\n",
    "                18:[True]*8, # ('Quoted', '389')\n",
    "                33:[True], # ('Quoted', '340')\n",
    "                70: [True], # ('Quoted', '343')\n",
    "                75: [True], # ('Quoted', '293')\n",
    "               },\n",
    "                'eli3': {\n",
    "                   20: [True, True], # ('Quoted', '504') \n",
    "                   113: [True, True], # ('Gemini', '546')\n",
    "                   135: [True]*5, # ('Quoted', '493')\n",
    "                   },\n",
    "            'mash': {\n",
    "                18: [True]*8, # ('Quoted', '217')\n",
    "                45: [True]*13, # ('Quoted', '62')\n",
    "                53: [True]*12, # ('Quoted', '143')\n",
    "                71: [True]*9, # ('Quoted', '139')\n",
    "                96: [True]*6, # ('Quoted', '130')\n",
    "                100: [True, True, True, True, True, True, True, True, False, False, False, True], # ('Quoted', '123')\n",
    "                132: [True]*7, # ('Quoted', '76')\n",
    "                133: [True]*27, # ('Quoted', '210')\n",
    "              }, \n",
    "               \n",
    "               'mh': {\n",
    "                   8: [True]*4, # ('Quoted', '163')\n",
    "                   30: [True]*2, # ('Quoted', '197')\n",
    "                   65: [True]*2, # ('Quoted', '155')\n",
    "                   118: [True]*2, # ('Quoted', '76')\n",
    "                   121: [True]*3, # ('Quoted', '116')\n",
    "                   143: [True]*4, # ('Quoted', '98')\n",
    "                   147: [True]*3, # ('Quoted', '147')\n",
    "               }\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3206cdb5-4bf3-485a-96fc-6ff92291942e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'[' was never closed (950372470.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[24], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    columns_to_remove = ['n-gram precision', 'Citation Count', 'n sentences', 'uuid', 'first_human_fluency_rating', 'first_human_utility_rating', 't2v_precision', columns_to_remove = ['n-gram precision', 'Citation Count', 'n sentences', 'uuid', 'first_human_fluency_rating', 'first_human_utility_rating', 't2v_precision', 'Fluency Rating', 'Perceived Utility Rating']\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '[' was never closed\n"
     ]
    }
   ],
   "source": [
    "datasets = ['nq', 'eli3', 'mash', 'mh']\n",
    "dataset_names = ['nq', 'eta3g', 'mash', 'mh']\n",
    "columns_to_remove = ['n-gram precision', 'Citation Count', 'n sentences', 'uuid', 'first_human_fluency_rating', 'first_human_utility_rating', 't2v_precision', columns_to_remove = ['n-gram precision', 'Citation Count', 'n sentences', 'uuid', 'first_human_fluency_rating', 'first_human_utility_rating', 't2v_precision', 'Fluency Rating', 'Perceived Utility Rating']\n",
    "for data_str, data_name in zip(datasets, dataset_names):\n",
    "    fp = baseline_fps[data_str]\n",
    "    baseline_df = pd.read_csv(fp+'.csv', index_col=False).reset_index(drop=True)\n",
    "    quoted_baseline_df = baseline_df[baseline_df['op']=='Quoted'].reset_index(drop=True)\n",
    "    # Fix the mismatches between vertex and the current sentence count\n",
    "    quoted_baseline_df = fix_mismatches(quoted_baseline_df, quoted_baseline_corrections[data_str])\n",
    "    identify_mismatches(quoted_baseline_df) # should print empty lists\n",
    "    # remove the T2V, coverage, and precision annotations\n",
    "    quoted_baseline_df = make_only_needs_citation(quoted_baseline_df)\n",
    "    check_needs_citation(quoted_baseline_df)\n",
    "    # rename 'Quoted' to 'Quoted Reeval'\n",
    "    quoted_baseline_df['op'] = 'Quoted Reeval'\n",
    "    # concatenate with the other baseline results\n",
    "    # baseline_df = pd.read_csv(baseline_fps[data_str]+'_cleaned_trimmed_needs_citation_only_NEW.csv', index_col=False)\n",
    "    baseline_df = baseline_dfs[data_str]\n",
    "    baseline_df = pd.concat([baseline_df, quoted_baseline_df])\n",
    "    # drop unused columns\n",
    "    baseline_df = baseline_df.drop(columns=columns_to_remove)\n",
    "    baseline_df = baseline_df.loc[:, ~baseline_df.columns.str.startswith(\"Unnamed\")]\n",
    "    # check again that only sentences requiring citation are kept\n",
    "    check_needs_citation(baseline_df)\n",
    "    # save\n",
    "    save_path = '../mturk_results/processed_results/'+data_name+'_mturk_eval_byQueryOP_baseline_needs_citation.csv' # this is a file used in plotting_by_metric\n",
    "    baseline_df.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d047353-2041-4b95-a08e-3f69ae770af0",
   "metadata": {},
   "source": [
    "# Save op files in the right folder with consistent naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d8795-e3f4-4507-82a7-1811b9d19353",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_str, data_name in zip(datasets, dataset_names):\n",
    "    op_df = op_dfs[data_str]\n",
    "    op_df = op_df.drop(columns=columns_to_remove)\n",
    "    op_df = op_df.loc[:, ~op_df.columns.str.startswith(\"Unnamed\")]\n",
    "    check_needs_citation(op_df) # check again that only sentences requiring citation are kept\n",
    "    save_path = '../mturk_results/processed_results/'+data_name+'_mturk_eval_byQueryOP_ops_needs_citation.csv' # this is a file used in plotting_by_metric\n",
    "    op_df.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba61b11f-aeab-4944-a3ca-f68fed16b845",
   "metadata": {},
   "source": [
    "# Add back the Quoted Reeval to the results over all sentences \n",
    "All sentences; not just those that require citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15feecc-5051-494e-abb0-b78f4019e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = '_cleaned_minus_one_coverage_UF'\n",
    "mturk_baseline_fps_all = {\n",
    "    'NQ': '../mturk_results/intermediate_results/nq_baseline_mturk_with_needs_citation_labels'+tag,\n",
    "    'Eta3G': '../mturk_results/intermediate_results/eli3_baseline_mturk_with_needs_citation_labels'+tag,\n",
    "    'MH': '../mturk_results/intermediate_results/mh_baseline_mturk_with_needs_citation_labels'+tag,\n",
    "    'MASH': '../mturk_results/intermediate_results/mash_baseline_mturk_with_needs_citation_labels'+tag,\n",
    "}\n",
    "\n",
    "mturk_op_fps_all = {\n",
    "    'NQ': '../mturk_results/intermediate_results/nq_mturk_with_needs_citation_labels2'+tag,\n",
    "    'Eta3G': '../mturk_results/intermediate_results/eli3_mturk_with_needs_citation_labels'+tag,\n",
    "    'MH': '../mturk_results/intermediate_results/mh_mturk_with_needs_citation_labels'+tag,\n",
    "    'MASH': '../mturk_results/intermediate_results/mash_mturk_with_needs_citation_labels'+tag,\n",
    "}\n",
    "mturk_fp = '../mturk_results/'\n",
    "for k1, k2 in zip(datasets, list(mturk_baseline_fps_all.keys())):\n",
    "    baseline_df = pd.read_csv(baseline_fps[k1]+'.csv', index_col=False).reset_index(drop=True)\n",
    "    quoted_baseline_df = baseline_df[baseline_df['op']=='Quoted'].reset_index(drop=True)\n",
    "    quoted_baseline_df['op'] = 'Quoted Reeval'\n",
    "    baseline_df = pd.read_csv(mturk_fp+mturk_baseline_fps_all[k2]+'.csv', index_col=False)\n",
    "    baseline_df = pd.concat([baseline_df, quoted_baseline_df])\n",
    "    baseline_df = baseline_df.drop(columns=columns_to_remove)\n",
    "    baseline_df = baseline_df.loc[:, ~baseline_df.columns.str.startswith(\"Unnamed\")]\n",
    "    save_path = '../mturk_results/processed_results/'+k2.lower()+'_mturk_eval_byQueryOP_baseline_all.csv' # this is a file used in plotting_by_metric\n",
    "    baseline_df.to_csv(save_path)\n",
    "    print('Saved to '+save_path)\n",
    "    op_df = pd.read_csv(mturk_fp+mturk_op_fps_all[k2]+'.csv', index_col=False)\n",
    "    save_path = '../mturk_results/processed_results/'+k2.lower()+'_mturk_eval_byQueryOP_ops_all.csv' # this is a file used in plotting_by_metric\n",
    "    op_df.to_csv(save_path)\n",
    "    print('Saved to '+save_path)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
